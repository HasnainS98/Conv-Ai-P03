{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkP9xzrm3IkNgsjC2kVk93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HasnainS98/Conv-Ai-P03/blob/main/Hasnain_Shafiq_Task01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook Documentation: Text Analysis with NLTK**\n",
        "\n",
        "This notebook performs basic text analysis using Python and the NLTK library, including tokenization and frequency distribution of tokens.\n",
        "\n",
        "Prerequisites\n",
        "\n",
        "Before running the code, ensure that nltk is installed and necessary datasets are downloaded."
      ],
      "metadata": {
        "id": "-1MKQ5ML66zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "AMtJOMxI7JEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n",
        "**bold text**\n",
        "\n",
        "The code imports key modules from the NLTK library for tokenizing text and calculating word frequency."
      ],
      "metadata": {
        "id": "wdE-Q7q_7KZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import nltk\n",
        "\n",
        "# Download the NLTK tokenizer data (punkt) for word_tokenize to work\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UPsVtDh24Ogq",
        "outputId": "72e5e133-deee-406a-c162-03771b715a1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing Text Data\n",
        "**bold text\\**\n",
        "\n",
        "\t1.\tText Tokenization: Tokenizes a sample text into individual words.\n",
        "\t2.\tToken Count: Calculates the total number of tokens in the text.\n",
        "\t3.\tFrequency Distribution: Computes the frequency of each token in the text."
      ],
      "metadata": {
        "id": "b85jIQHf7Stn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = \"\"\"Artificial intelligence is transforming industries across the world.\n",
        "From healthcare to finance, AI applications are creating new possibilities.\n",
        "Machine learning, a subset of AI, is helping to predict outcomes and optimize processes.\n",
        "As AI continues to evolve, it raises important ethical and societal questions.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "print(\"List of tokens:\", tokens)\n",
        "\n",
        "num_tokens = len(tokens)\n",
        "print(\"Number of tokens:\", num_tokens)\n",
        "\n",
        "frequency_distribution = FreqDist(tokens)\n",
        "print(\"Frequency of each token:\", frequency_distribution)\n",
        "\n",
        "for token, freq in frequency_distribution.items():\n",
        "    print(f\"Token: {token}, Frequency: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-jUJey5U3yzy",
        "outputId": "5623a260-bd7d-4f88-9406-bf84e3d13d24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of tokens: ['Artificial', 'intelligence', 'is', 'transforming', 'industries', 'across', 'the', 'world', '.', 'From', 'healthcare', 'to', 'finance', ',', 'AI', 'applications', 'are', 'creating', 'new', 'possibilities', '.', 'Machine', 'learning', ',', 'a', 'subset', 'of', 'AI', ',', 'is', 'helping', 'to', 'predict', 'outcomes', 'and', 'optimize', 'processes', '.', 'As', 'AI', 'continues', 'to', 'evolve', ',', 'it', 'raises', 'important', 'ethical', 'and', 'societal', 'questions', '.']\n",
            "Number of tokens: 52\n",
            "Frequency of each token: <FreqDist with 40 samples and 52 outcomes>\n",
            "Token: Artificial, Frequency: 1\n",
            "Token: intelligence, Frequency: 1\n",
            "Token: is, Frequency: 2\n",
            "Token: transforming, Frequency: 1\n",
            "Token: industries, Frequency: 1\n",
            "Token: across, Frequency: 1\n",
            "Token: the, Frequency: 1\n",
            "Token: world, Frequency: 1\n",
            "Token: ., Frequency: 4\n",
            "Token: From, Frequency: 1\n",
            "Token: healthcare, Frequency: 1\n",
            "Token: to, Frequency: 3\n",
            "Token: finance, Frequency: 1\n",
            "Token: ,, Frequency: 4\n",
            "Token: AI, Frequency: 3\n",
            "Token: applications, Frequency: 1\n",
            "Token: are, Frequency: 1\n",
            "Token: creating, Frequency: 1\n",
            "Token: new, Frequency: 1\n",
            "Token: possibilities, Frequency: 1\n",
            "Token: Machine, Frequency: 1\n",
            "Token: learning, Frequency: 1\n",
            "Token: a, Frequency: 1\n",
            "Token: subset, Frequency: 1\n",
            "Token: of, Frequency: 1\n",
            "Token: helping, Frequency: 1\n",
            "Token: predict, Frequency: 1\n",
            "Token: outcomes, Frequency: 1\n",
            "Token: and, Frequency: 2\n",
            "Token: optimize, Frequency: 1\n",
            "Token: processes, Frequency: 1\n",
            "Token: As, Frequency: 1\n",
            "Token: continues, Frequency: 1\n",
            "Token: evolve, Frequency: 1\n",
            "Token: it, Frequency: 1\n",
            "Token: raises, Frequency: 1\n",
            "Token: important, Frequency: 1\n",
            "Token: ethical, Frequency: 1\n",
            "Token: societal, Frequency: 1\n",
            "Token: questions, Frequency: 1\n"
          ]
        }
      ]
    }
  ]
}